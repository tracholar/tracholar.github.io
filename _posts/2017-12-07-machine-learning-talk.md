---
layout: post
title: "机器学习漫谈"
description: "机器学习漫谈，人工智能漫谈！"
category: "machine-learning"
tags: ["机器学习","深度学习"]
---

前不久，国务院发布了《新一代人工智能发展规划》[1]，将人工智能上升到国家战略高度，中国希望借助人工智能重回世界科技的中心；
紧接着科技部又发布了人工智能发展规划[2]，并依托四大单位：百度、阿里、腾讯、科大讯飞，建立新一代人工智能创新平台！
如果要问现在什么是风口行业，毫无疑问是人工智能！机器学习是当前实现人工智能的一种途径，也是目前的最佳途径！
在这篇文章中，将自己的机器学习的些许感悟，总结起来，希望着眼当下，展望未来。

* 目录
{:toc}


## 机器学习之道

### 机器学习的本质——归纳法
说到机器学习，几乎都会与另外一个词“人工智能”挂钩，现在人工智能的火爆程度丝毫不亚于2002年左右的互联网的火爆。
还有一个词也是业界津津乐道的，那就是“深度学习”。
如果你上google搜索 machine learning 和 deep learning，你会发现这两个词的搜索指数非常相似！
事实上，机器学习这个领域已经发展很多年了，这一波机器学习的火爆正是伴随着深度学习而爆发的，尤其是在2012年的两个里程碑式的工作：

1. Hinton和学生Alex利用一个深层的卷积网络把ImageNet比赛刷到的新的记录，拿到当年的冠军[3]。
2. Hinton和微软的研究者将DNN用于语音识别的声学模型，为10年未有明显突破的语音识别技术带来了新的曙光[4]！

![机器学习和深度学习的搜索指数](/assets/images/ml-dl-search-index.png)

虽然这一波机器学习的火爆是由于深度学习的突破，但是很多学者表示，深度学习并非什么新的技术，所用的神经网络DNN、CNN、RNN都是之前就提出过的，更多的改进是由于算力、数据量的提升，当然并不是说模型没有突破，模型上也有很多改进，但都谈不上突破式的创新。
事实上，这种说法基本是正确的，直到生成对抗网络GAN的提出，LeCun把GAN称作“过去十年机器学习界最有趣的idea”。
但是，不论如何，深度学习带来的飞跃确实是看得见的！看看现在无论是初创公司还是传统公司，言必称自己是人工智能公司就知道有多么大影响力了！

不论是这一波火爆的深度学习，还是经典的机器学习算法，他们的本质并没有什么区别，都是 **利用某种算法从数据中自动归纳出有意义的规律的一种方法**。

我们知道，人类的推理方法大致可以分为两种，一种是演绎法，另一种是归纳法。

所谓演绎推理(Deductive Reasoning)，就是从一般性的前提出发，通过推导即“演绎”，得出具体陈述或个别结论的过程。演绎推理的逻辑形式对于理性的重要意义在于，它对人的思维保持严密性、一贯性有着不可替代的校正作用。我们熟知的很多数学证明方法，例如通过简单的几条公理，推导出整个欧式几何大厦的推理过程，就是典型的演绎推理。
下面是演绎推理里面一个典型的三段论推理的例子：

> 1. 知识分子都是应该受到尊重的，
> 2. 人民教师都是知识分子
> 3. 所以，人民教师都是应该受到尊重的。

演绎推理的核心思想就是从一般到特殊，将一些已经为真的通用性结论应用到具体的问题当中，得到具体的情况下的结论。这种推理方式保证了推理的严密性！在上述例子中，前两条就是一般性结论，知识分子是比人民教师更大的概念，第三条的结论就是将第一条结论应用到人民教师这个具体的个体上得到的更具体的结论！

有趣的是，柯南道尔的著名小说中《福尔摩斯》中的大侦探福尔摩斯也十分推崇“演绎法”！为此，老美还专门拍了一部剧《福尔摩斯：基本演绎法》！
只不过，福尔摩斯所声称的一般性结论和推理方式非常人能理解！


![演绎法与归纳法](/assets/images/deductive-inductive.png)

事实上，在早期的人工智能中，采用的也正是这种演绎推理。例如早期的专家系统，定理的机器证明，符号计算等等。
在专家系统中，知识被表达成很多条件命题，推理系统利用这些知识进行演绎推理得出结论！

而归纳法是根据一类事物的部分对象具有某种性质的有限观察，推出这类事物的所有对象都具有这种性质的推理，叫做归纳推理（简称归纳）。归纳是从特殊到一般的过程，它属于合情推理。通常归纳法难以保证结论是可靠的，例如，下面就是经典的归纳法的例子：

> **黑天鹅事件**  
> 17世纪之前，欧洲看到过的天鹅都是白色的，所以当时欧洲人归纳出一个结论：天鹅都是白色的！
> 直到后来，欧洲人发现了澳洲，看到了当地的黑天鹅，人们才认识到这个结论是错误的！

从有限的经验归纳出来的结论当然不见得是可靠的，但是数学上也有完全归纳法，可以保证结论是可靠的的例子，我们以前学过的数学归纳法，从命题$$P_n$$推到$$P_{n+1}$$就是一个例子！

从逻辑推理的角度来看，我们现在所用的机器学习就是先观察到一些数据，然后从这有限的数据中归纳出一些有用的规律的过程！
因此，**机器学习本质上就是在做归纳推理**，并且是不完全的归纳法！我们前面说到，这种不完全归纳法无法保证结论的正确性，所以如果机器学习模型预测错了，请不要怪他，因为它是在做不完全归纳，肯定会犯错的！但是这并不意味着就没有用，事实上我们人类很多经验都是通过不完全归纳法归纳出来的，甚至可以说几乎所有实际的经验都来源于不完全归纳，完全归纳法只有在数学上才存在。只要归纳的结论大多数情况下是对的，那么他就是有用的！

前面我们说了，机器学习本质就是从数据中自动归纳出有用的规律。那么，反过来，如果一个任务是从数据中去找规律，那么这件事就可以试试用机器学习来做，往往可以做得比人还好！下面是一些已经应用机器学习算法的例子

1. xxR预估：CTR（点击率），CVR（转化率、下单率），司机接单率 etc。各种R的预估是应用机器学习的一个典型的场景，也是目前机器学习算法应用最多的场景之一！
2. 视听说听读写：CV（机器视觉），ASR（自动语音识别），STT（语音合成），NLP（自然语言处理），MT（机器翻译），QA（问答）etc。这个场景也是目前人工智能吹得最火的场景，各种超越人类！
3. 生物医学：基因工程、医学图像、诊断！比如，Google最近就声称利用机器学习算法对电子病历进行分析[5]，未来机器学习在医学上的应用应该价值重大！
4. 物理：希格斯玻色子挑战[6]，利用算法找到区别于背景的有价值事件信号；量子多体波函数的建模[7] etc
5. 化学：利用机器学习预测化学分子性质[8-10]，研究人员通过理论仿真了很多分子的性质与参数关系，但是每次仿真都耗时巨大，于是想到了利用已有的仿真数据，建立一个机器学习模型来学习这个预测函数！
6. 计算机科学：利用机器学习做数据库索引[11]，Google科学家重新审视了数据库中的B+树索引，发现它就是一个回归树，因此想到用机器学习方法来建立索引。

纵观以上应用场景，可以发现都是有了很多数据，需要从数据中归纳出一些结论，因此这些问题可能就很适合应用机器学习来解决！
如果你也想在工作中应用机器学习，那么你得首先思考一下，你的工作内容是否可以看做从数据中找到一些规律的问题，如果答案是肯定的，那么就不要犹豫了，马上试试机器学习的方法，说不定就会有意外的收获！

### 监督学习的本质——函数拟合

机器学习的方法大致可分为两大类，监督学习和无监督学习，前者是目前应用最为广泛的方法。两者的区别在于观测的数据是否有标注！
简单来说，如果给你很多照片，要你用算法从这些数据中建立一个模型来找出人像和风景照，那么就是无监督的！如果这些照片已经是标注好的，也就是说每张照片都打上了一个标签，告诉你是人像还是风景照，那么这个问题就是监督学习！

通常监督学习比无监督学习更容易，因为有了监督信号告诉你对还是不对！**监督学习本质上就是在函数拟合**！
比如上面的例子，输入一张照片，要你输出这张照片是人像还是风景照！这就是一个数学函数

$$
h(X) = \begin{cases}
        1, \text{如果照片X是人像} \\
        -1, \text{如果照片X是风景照}
        \end{cases}
$$

函数拟合这件事情，最早可以追溯到18世纪大数学家高斯的[最小二乘法](https://en.wikipedia.org/wiki/Least_squares
)。早在18世纪，数学家高斯就开始研究怎么根据观察到的一堆数据，把拟合最好的直线找出来的问题。这个方法，在高中数学中就学习过，方法也很简单，就是找到一条直线$$\hat{y} = ax + b$$使得拟合误差$$\sum_i (y - \hat{y})^2$$最小！利用很简单的数学推导就可以得到最佳的参数！这个方法就是最小二乘法，可以应用到高维情况，最优参数有解析解！

![高斯和最小二乘法](/assets/images/least_squares.png)

高斯最小二乘法更现在机器学习用的线性回归模型并没有什么太大区别，只是在损失函数上做了一些适应于特殊环境的改进。
监督学习另外一类问题就是前面的例子中提到的问题，分类问题。分类和回归的区别在于拟合的目标变量$$y$$的取值构成的是无限集合还是有限集合。如果是无限的，通常认为是回归问题，比如预测房价；如果是有限集合，通常认为是分类问题，比如预测股价涨和跌，照片是哪种类型等等。
分类问题要拟合的函数是不连续的，因此难以直接拟合。除了一些决策树算法可以直接拟合不连续的分类函数外，大多数算法都是通过拟合样本属于每一类的概率来间接拟合这个不连续的函数。一旦这个概率拟合好了，然后找出概率最大的作为输出就得到了最终的分类函数了！

$$
\hat{y} = \arg\max_i P(y=i|X)
$$

线性分类模型对输入做线性加权打分后，然后用softmax归一化得到概率，最优的权重通过极大似然估计得到。

不论是简单的线性模型还是现在火热的深层模型（深度学习），**本质上都是在拟合一个函数**！

## 机器学习之术



## 参考文献
1. 国务院关于印发新一代人工智能发展规划的通知 <http://www.gov.cn/zhengce/content/2017-07/20/content_5211996.htm>
2. 科技部召开新一代人工智能发展规划暨重大科技项目启动会 <http://www.most.gov.cn/kjbgz/201711/t20171120_136303.htm>
3. Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.
4. Hinton G, Deng L, Yu D, et al. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups[J]. IEEE Signal Processing Magazine, 2012, 29(6): 82-97.
5. Rajkomar A, Oren E, Chen K, et al. Scalable and accurate deep learning for electronic health records[J]. arXiv preprint arXiv:1801.07860, 2018.
6. <https://www.kaggle.com/c/Higgs-boson>
7. Gao X, Duan L M. Efficient representation of quantum many-body states with deep neural networks[J]. arXiv preprint arXiv:1701.05039, 2017.
8. Rupp M, Tkatchenko A, Müller K R, et al. Fast and accurate modeling of molecular atomization energies with machine learning[J]. Physical review letters, 2012, 108(5): 058301.
9. Gilmer J, Schoenholz S S, Riley P F, et al. Neural message passing for quantum chemistry[J]. arXiv preprint arXiv:1704.01212, 2017.
10. <https://www.leiphone.com/news/201704/EHV2LSPT43FrGWJQ.html>
11.
