---
layout: post
title: "深入理解AUC"
description: ""
category: "machine-learning"
tags: ["机器学习","AUC"]
---

在机器学习的评估指标中，AUC是一个最常见也是最常用的指标之一。
AUC本身的定义是基于几何的，但是其意义十分重要，应用十分广泛。
本文作者深入理解AUC，并总结于下。

* 目录
{:toc}

## AUC是什么

在统计和机器学习中，常常用AUC来评估二分类模型的性能。AUC的全称是 area under the curve，即曲线下的面积。
通常这里的曲线指的是[受试者操作曲线(Receiver operating characteristic, ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)。
相比于准确率、召回率、F1值等依赖于判决阈值的评估指标，AUC则没有这个问题。

ROC曲线早在第二次世界大战期间就被使用在电子工程和雷达工程当中，被用于军事目标检测。
后来，ROC曲线也被应用到心理学、医学、机器学习和数据挖掘等领域的模型性能评估。

对于二分类问题，预测模型会对每一个样本预测一个得分s或者一个概率p。
然后，可以选取一个阈值t，让得分s>t的样本预测为正，而得分s<t的样本预测为负。
这样一来，根据预测的结果和实际的标签可以把样本分为4类：

|     | 正样本 |  负样本
|-----|--------|--------
|预测为正|  TP(真正例) |  FP(假正例)
|预测为负|  FN(假负例) |  TN(真负例)

随着阈值t选取的不同，这四类样本的比例各不相同。定义真正例率TPR和假正例率FPR为：

$$
\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}} \\
\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}
$$

对于真正例率TPR，分子是得分>t里面正样本的数目，分母是总的正样本数目。
而对于假正例率FPR，分子是得分>t里面负样本的数目，分母是总的负样本数目。
因此，如果定义$$N_+(t), N_-(t)$$分别为得分大于t的样本中正负样本数目，$$N_+, N_-$$为总的正负样本数目，
那么TPR和FPR可以表达为阈值t的函数

$$
\text{TPR}(t) = \frac{N_+(t)}{N_+} \\
\text{FPR}(t) = \frac{N_-(t)}{N_-}
$$

随着阈值t的变化，TPR和FPR在坐标图上形成一条曲线，这条曲线就是ROC曲线。
显然，如果模型是随机的，模型得分对正负样本没有区分性，那么得分大于t的样本中，正负样本比例和总体的正负样本比例应该基本一致。
也就是说

$$
\frac{N_+(t)}{N_-(t)} = \frac{N_+}{N_-}
$$

结合上面的式子可知TPR和FPR相等，对应的ROC曲线是一条直线！

反之，如果模型的区分性非常理想，也就是说正负样本的得分可以完全分开，所有的正样本都比负样本得分高，此时ROC曲线表现为「 字形。
因为正例得分都比负例搞，所以要么TPR=0要么FPR=0！


![ROC曲线](/assets/images/ROC_curves.svg)

实际的模型的ROC曲线则是一条上凸的曲线，介于随机和理想的ROC曲线之间。而ROC曲线下的面积，即为AUC！

$$
\text{AUC} = \int_{t=\infty}^{-\infty} y(t) d x(t)
$$

这里的x和y分别对应TPR和FPR，也是ROC曲线的横纵坐标。

## AUC的概率解释

### 概率解释的证明
AUC常常被用来作为模型排序好坏的指标，原因在于AUC可以看做随机从正负样本中选取一对正负样本，其中正样本的得分大于负样本的概率！
这个结论很容易证明，考虑随机取得这对正负样本中，负样本得分在$$[t, t+\Delta t]$$之间的概率为

$$
\begin{align*}
& P(t \le s_- < t+\Delta t) \\
    = &P( s_- \gt t) - P(s_- > t+\Delta t) \\
    = & \frac{N_-(t)  - N_-(t+\Delta t)}{N_-} \\
    = & x(t) - x(t +\Delta t) =  - \Delta x(t)
\end{align*}
$$

如果$$\Delta t$$很小，那么该正样本得分大于该负样本的概率为

$$
P(s_+ > s_- | t \le s_- < t+\Delta t) \\
\approx P(s_+ > t) = \frac{N_+(t)}{N_+} = y(t)
$$

所以，

$$
\begin{align*}
 & P(s_+ > s_- )  \\
= & \sum P(t \le s_- < t+\Delta t) P(s_+ > s_- | t \le s_- < t+\Delta t) \\
= & -\sum y(t) \Delta x(t) \\
= & -\int_{t=-\infty}^{\infty} y(t) d x(t) \\
= & \int_{t=\infty}^{-\infty} y(t) d x(t)
\end{align*}
$$

注意积分区间，$$t=-\infty$$对应ROC图像最右上角的点，而$$t=\infty$$对应ROC图像最左下角的点。所以，计算面积是$$\int_{t=\infty}^{-\infty}$$。
可以看出，积分项里面实际上是这样一个事件的概率：**随机取一对正负样本，负样本得分为t且正样本大于t！**
因此，对这个概率微元积分就可以到正样本得分大于负样本的概率！

### AUC的排序特性

根据上述概率解释，AUC实际上在说一个模型把正样本排在负样本前面的概率！
所以，AUC常用在排序场景的模型评估，比如搜索和推荐等场景！
这个解释还表明，如果将所有的样本的得分都加上一个额外的常数，并不改变这个概率，因此AUC不变！
因此，在广告等需要绝对的点击率场景下，AUC并不适合作为评估指标，而是用logloss等指标。

### AUC对正负样本比例不敏感

利用概率解释，还可以得到AUC另外一个性质，对正负样本比例不敏感。
在训练模型的时候，如果正负比例差异比较大，例如正负比例为1:1000，训练模型的时候通常要对负样本进行下采样。当一个模型训练完了之后，用负样本下采样后的测试集计算出来的AUC和未采样的测试集计算的AUC基本一致，或者说前者是后者的无偏估计！
如果采样是随机的，对于给定的正样本，假定得分为$$s_+$$，那么得分小于$$s_+$$的负样本比例不会因为采样而改变！
例如，假设采样前负样本里面得分小于$$s_+$$的样本占比为70%，如果采样是均匀的，即$$>s_+$$的负样本和$$<s_+$$的负样本留下的概率是相同的，那么显然采样后这个比例仍然是70%！
这表明，该正样本得分大于选取的负样本的概率不会因为采样而改变，也就是$$y(t) d x(t)$$是不变的，因此，AUC也不变！


## AUC的优化

采用极大似然估计对应的损失函数是logloss，因此极大似然估计的优化目标并不是AUC。
在一些排序场景下，AUC比logloss更贴近目标，因此直接优化AUC可以达到比极大似然估计更好的效果。
实际上，pairwise的目标函数就可以看做一种对AUC的近似。因为损失函数都是作用与正负样本得分差之上！
例如，

-----------|--------------------------------------
rank-SVM   | $$\max(0, - s_+ + s_- + \Delta)$$
rank-net   | $$\log (1 + \exp(- (s_+ - s_-)))$$
指数损失    |  $$\exp(- (s_+ - s_-))$$
TOP 损失   |  $$\sum_s \max(0, - s_c + s + \Delta)$$

显然，这些损失函数都是对$$s_+<s_-$$的正负样本对进行惩罚！
此外，也有一些其它对AUC近似度更好的损失函数，例如

$$
\mathbf{E} \left[ (1-w^T(s_+ - s_-))^2 \right] \\
= \frac{1}{n_+n_-} \sum_{i=1}^{n_+} \sum_{j=1}^{n_-}  (1-w^T(s_{i}^+ - s_{j}^-))^2
$$

$$s_i^+, s_j^-$$分别表示正例和负例的得分。
这解释了为什么某些问题中，利用排序损失函数比logloss效果更好，**因为在这些问题中排序比概率更重要**！
