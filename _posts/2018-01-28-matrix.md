---
layout: post
title: "深入理解矩阵"
description: ""
category: "math"
tags: ["矩阵","线性代数"]
---

刚开始学习矩阵的时候，总会很好奇，为什么会有矩阵，矩阵的乘法运算为什么是这个样子，矩阵的意义到底是什么？
这些疑惑，随着学习的深入，会逐渐被揭开，本文就是作者的疑惑被揭开后的总结，希望对刚学习线性代数的读者有所帮助，对想深入理解矩阵的读者也是值得一看的文章。

* 目录
{:toc}

## 矩阵的本质

相信很多读者第一次了解矩阵都是从解线性方程开始的，我们将从一个很接近的角度来得到矩阵，认为矩阵的本质就是有限维线性空间中的 **线性变换**.

我们还是从一维的情况开始吧，也就是标量的线性变换 $$y = ax$$。所谓一个变换$$y = f(x)$$是线性的，是指这个变换遵循两个线性运算的规律：

1. 对于数乘可以交换，$$f(\lambda x) = \lambda f(x)$$
2. 对于元素加法可交换， $$f(x_1 + x_2) = f(x_1) + f(x_2)$$

对于第一条规律，标量线性变换显然是满足的，因为$$a \cdot(\lambda x) = \lambda (a x)$$，这是由乘法结合律带来的。
对于第二条规律，利用乘法对加法的分配率也容易验证，$$a(x_1+x_2) = a x_1 + a x_2$$。
简单地理解，**线性变换就是没有常数项的一次函数**！
显然，一维情况的线性变换可以只用一个常数a来描述就可以了，不需要其他参数！

那么，对于高维情况呢？我们考虑最简单的二维情况，一般情况下，二维的线性变换可以表达为没有常数项的二元一次函数

$$
y_1 = a_{11} x_1 + a_{12} x_2 \\
y_2 = a_{21} x_1 + a_{22} x_2
$$

相比一维情况只要1个参数就可以描述，二维则需要4个参数！依次类推下去，n维线性变换自然需要$$n^2$$个参数才能描述！
把这些参数排列成方正就是我们的矩阵了！

$$
A = \left[ \begin{matrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{matrix} \right]
$$

## 矩阵的乘法

我在第一次学习矩阵的乘法的时候，十分好奇为什么矩阵乘法是那样的定义。
这里，我们通过线性变换的角度比较容易说明。

我们还是从一维的情况说起吧，现在我有两个线性变换 $$y = a x, z = b y$$，我想用一个变换$$z = c x$$来代替，
那么，显然有$$c= b\cdot a$$！也就是说，在一维情况，两个数的乘法实际上可以看做是用一个线性变换$$c$$来代替两个变换$$a, b$$的依次变换的结果，即

$$
z = c \cdot x = b \cdot (a \cdot x)
$$

我们把这个思想运用到高维不就可以得到矩阵乘法了吗？
假设两个矩阵为A和B，对应的变换是$$y = A x, z = B y$$，我们想用一个矩阵C来代替这两个变换的依次作用的效果，即

$$
z = C x = B(A x)
$$

我们把上式右边展开可得

$$
\begin{align*}
z_{11} =& b_{11}(a_{11}x_1 + ... a_{1n} x_n) + ... + b_{1n}(a_{n1}x_1 + ... a_{nn} x_n) \\
= &\left(b_{11} a_{11} + ... + b_{1n} a_{n1}\right) x_1 + \\
  &\left(b_{11} a_{12} + ... + b_{1n} a_{n2}\right) x_2 + \\
  & ...\\
  &\left(b_{11} a_{1n} + ... + b_{1n} a_{nn}\right) x_n
\end{align*}
$$

因此可知

$$
c_{11} = b_{11} a_{11} + ... + b_{1n} a_{n1} \\
...\\
c_{1n} = b_{11} a_{1n} + ... + b_{1n} a_{nn}
$$

把上述代入过程用求和符号改写可以简化为

$$
z_{i} = \sum_j c_{ij} x_j \\
= \sum_k b_{ik} \left(\sum_j a_{kj} x_j\right) \\
= \sum_j \left(\sum_k b_{ik} a_{kj} \right) x_j
$$

最后一个等式利用了求和符号的交换，这表明

$$
c_{ij} = \sum_k b_{ik} a_{kj}
$$

这就是矩阵乘法的运算法则，把B矩阵第i行与A矩阵第j列的内积作为C矩阵的第(i, j)个元素的值！
这表明，矩阵乘法运算法则是一种必然的结果，而不是某种人为规定的奇怪的运算法则！
矩阵的乘法，实际上就是两个线性变换的乘法，变换的乘法运算就是定义为依次映射，

$$
(B \cdot A) x = B \cdot (A x)
$$

**这种定义是为了让乘法满足结合律很自然的结果**！

## 矩阵的特征值和特征向量
在学习特征值和特征向量的时候，很多人都会很迷惑，这搞得是啥玩意儿！？但是，只要把来龙去脉搞清楚，就不难理解了。
特征值和特征向量是最重要的概念之一！

我们还是从一维开始说起，一维的线性变换就是简单的把x放大a倍！
但是，这个直观的图像在高维情况就不那么直观了！我们还是从二维说起。
这种不直观的根本原因在于交叉项$$a_{12}, a_{21}$$的存在，如果这两项为0，那么矩阵就是对角阵

$$
A = \left[ \begin{matrix} a_{11} & 0 \\ 0 & a_{22} \end{matrix} \right]
$$

这个对角矩阵有个直观的图像，经过它变换的向量，在$$x, y$$两个方向上分别放大$$a_{11}, a_{22}$$倍！
这种情况，我们也说在这种变换下，不同坐标间没有耦合，各坐标是独立伸缩变换的！

对于一般的方阵，是否也有类似的图像？显然对于一般的方阵A，肯定不是在$$x, y$$两个方向上的独立伸缩变换。
那是不是可以找到两个独立的方向呢？如果能够找到，那么方阵A可以看做一个旋转变换加上两个独立方向上的伸缩变换，最后再旋转回来这三个变换构成！写成公式就是

$$
A = T^{-1} \Lambda T
$$

其中$$T$$是一个旋转变换，$$\Lambda$$是对角方阵代表两个方向上的独立伸缩变换。
没错，这就是矩阵的相似对角化！

线性代数的知识告诉我们，对于一般的方阵，并不都是可以相似对角化的，只能相似到一个[若尔当标准型](https://en.wikipedia.org/wiki/Jordan_normal_form)。
但是如果A是对称阵（对于复数则是厄米对称），那么答案就是肯定的！

假设对于对称矩阵A，两个独立的方向单位向量是$$v_1, v_2$$，那么有

$$
Av_1 = \lambda_1 v_1, \\
Av_2 = \lambda_2 v_2
$$

$$\lambda_1, \lambda_2$$是两个实数，代表这两个独立方向上的伸缩变换比例！
并且这两个方向向量构成一组标准正交基！因此，对于一般的向量x，可以选取这两个向量作为基向量，重新表达

$$
x = x_1 v_1 + x_2 v_2
$$

那么，矩阵A对向量x的变换为

$$
A x = (x_1 \lambda_1) v_1 + (x_2 \lambda_2) v_2
$$

也就是向量x在$$v_1,v_2$$两个独立的正交方向上分别放大了 $$\lambda_1, \lambda_2$$倍！

因此，特征向量可以看做矩阵的多个主方向，在这些方向上，矩阵对应的变换将向量在这些方向上的分量分别伸缩$$\lambda_i$$倍！

这些主方向和特征值在不同场景都是有特定意义的。


例如，在描述曲面上的曲率的时候，会用一个曲率张量（就是一个二阶对称方阵）来描述，该张量的两个特征向量就是两个曲率最大和最小的方向，而两个特征值就是这两个方向的曲率！

平面上的二次曲线都是用一个二次型表示，二次型对应的对称方阵的两个特征向量就是长短轴的方向，而两个特征值就是长短轴的大小（相差一个常数）！

在量子力学中，物理量都是用算法表示，在有限维空间就是矩阵，其对应的特征向量就是本征态，特征值就是物理量的测量值！
